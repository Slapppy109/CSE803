{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> Kevin Le </div>\n",
    "<div style=\"text-align: right\"> CSE 803 </div>\n",
    "<div style=\"text-align: right\"> Hw6 </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import open3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to compute the projection matrix P that goes from world 3D coordinates to 2D image coordinates. Recall that using homogeneous coordinates the equation for moving from 3D world to 2D camera\n",
    "coordinates is:\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "u \\\\\n",
    "v \\\\\n",
    "1\n",
    "\\end{pmatrix} \\equiv P\n",
    "\n",
    "\\begin{pmatrix}\n",
    "X \\\\\n",
    "Y \\\\\n",
    "Z \\\\\n",
    "1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "In part 1, you’re given corresponding point locations in pts2d-norm-pic.txt and pts3d-norm.txt,\n",
    "which corresponds to a camera projection matrix. Solve the projection matrix P and include it in your report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given \n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "u \\\\\n",
    "v \\\\\n",
    "1\n",
    "\\end{pmatrix} \\equiv \n",
    "\\begin{pmatrix}\n",
    "\n",
    "P_{11} & P_{12} & P_{13} & P_{14} \\\\\n",
    "P_{21} & P_{22} & P_{23} & P_{24}\\\\\n",
    "P_{31} & P_{32} & P_{33} & P_{34}\n",
    "\\end{pmatrix}\n",
    "\n",
    "\\begin{pmatrix}\n",
    "X \\\\\n",
    "Y \\\\\n",
    "Z \\\\\n",
    "1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "Thus:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "X_{1} & Y_{1} & Z_{1} & 1 & 0 & 0 & 0 & -u_{1}X_{1} & -u_{1}Y_{1} & -u_{1}Z_{1} & -u_{1} \\\\\n",
    "0 & 0 & 0 & 0 & X_{1} & Y_{1} & Z_{1} & -v_{1}X_{1} & -v_{1}Y_{1} & -v_{1}Z_{1} & -v_{1} \\\\\n",
    "\n",
    "... & ... & ... & ... & ... & ... & ... & ... & ... & ... & ...\\\\\n",
    "X_{N} & Y_{N} & Z_{N} & 1 & 0 & 0 & 0 & -u_{N}X_{N} & -u_{N}Y_{N} & -u_{N}Z_{N} & -u_{N} \\\\\n",
    "0 & 0 & 0 & 0 & X_{N} & Y_{N} & Z_{N} & -v_{N}X_{N} & -v_{N}Y_{N} & -v_{N}Z_{N} & -v_{N} \\\\\n",
    "\\end{bmatrix}_{2N \\times 6}\n",
    "\\begin{bmatrix}\n",
    "P_{11} \\\\ P_{12} \\\\ P_{13} \\\\\n",
    "P_{21} \\\\ P_{22} \\\\ P_{23} \\\\\n",
    "P_{31} \\\\ P_{32} \\\\ P_{33} \\\\\n",
    "\\end{bmatrix}\n",
    "= \n",
    "\\begin{bmatrix}\n",
    "0 \\\\ 0 \\\\\n",
    "... \\\\ \n",
    "0 \\\\ 0 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.460996   -0.29451331 -0.00297082 -0.00135929]\n",
      " [-0.0507238  -0.05488378 -0.54314532 -0.05294097]\n",
      " [ 0.10916895  0.17962108 -0.03105869  0.59345849]]\n"
     ]
    }
   ],
   "source": [
    "p2d = np.loadtxt('./data/pts2d-norm-pic.txt')\n",
    "p3d = np.loadtxt('./data/pts3d-norm.txt')\n",
    "\n",
    "# Turn Homogenous\n",
    "p2d = np.hstack((p2d, np.ones((p2d.shape[0], 1))))\n",
    "p3d = np.hstack((p3d, np.ones((p3d.shape[0], 1))))\n",
    "\n",
    "A = np.zeros((2*p2d.shape[0], 12))\n",
    "\n",
    "for i in range(6):\n",
    "    A[2*i] = np.array([p3d[i][0], p3d[i][1], p3d[i][2], 1, 0, 0, 0, 0, \\\n",
    "            -1 * p2d[i][0] * p3d[i][0], -1 * p2d[i][0] * p3d[i][1], \\\n",
    "                -1 * p2d[i][0] * p3d[i][2], -1 * p2d[i][0]])\n",
    "    A[2*i + 1] = np.array([0, 0, 0, 0, p3d[i][0], p3d[i][1], p3d[i][2], \\\n",
    "        1, -1 * p2d[i][1] * p3d[i][0], -1 * p2d[i][1] * p3d[i][1], \\\n",
    "            -1 * p2d[i][1] * p3d[i][2], -1 * p2d[i][1]])\n",
    "\n",
    "eig_val, eig_vec = np.linalg.eig(A.T @ A)\n",
    "P = eig_vec[:,np.argmin(eig_val)].reshape(3,4)\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, \n",
    "$$\n",
    "P =\n",
    "\\begin{bmatrix}\n",
    "0.460996 & -0.29451331 & -0.00297082 & -0.00135929 \\\\\n",
    "-0.0507238 & -0.05488378 & -0.54314532 & -0.05294097 \\\\\n",
    "0.10916895 & 0.17962108 & -0.03105869 & 0.59345849]\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation of the Fundamental Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next part of this project is estimating the mapping of points in one image to lines in another by means\n",
    "of the fundamental matrix. This will require you to use similar methods to those in part 1. You’ll work on\n",
    "the Wizarding Temple dataset. \n",
    "\n",
    "Recall that the definition of the Fundamental Matrix is:\n",
    "$$\n",
    "\\begin{pmatrix} u^{\\prime} & v^{\\prime} & 1 \\end{pmatrix} \n",
    "\\begin{pmatrix} \n",
    "f_{11} + f_{12} + f_{13} \\\\\n",
    "f_{21} + f_{22} + f_{23} \\\\\n",
    "f_{31} + f_{32} + f_{33} \\\\\n",
    "\\end{pmatrix} = 0\n",
    "$$\n",
    "\n",
    "Here are detailed instructions:\n",
    "1. Load corresponding points from temple.npz.\n",
    "2. Implement eight-point algorithm and estimate the fundamental matrix F. **Report** F in your report. Remember to normalize F so that the last entry of F is 1. Hint: You should normalize the\n",
    "data first. For example, scale the data by dividing each coordinate by the maximum of the images width and height. You may validate your implementation by comparing against the output of\n",
    "cv2.findFundamentalMat, **but you will be graded on your eight-point algorithm**.\n",
    "3. Show epipolar lines. **Include** the visualization in your report. A sample output is shown as Figure\n",
    "2. You can call draw epipolar(img1, img2, F, pts1, pts2) in utils.py to generate an image like the sample output. Note that you only need to show around 10 points and their\n",
    "corresponding epipolar lines so that we can verify your calculation is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triangulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is extracting 3D points from 2D points and camera matrices, which is called triangulation. Let\n",
    "$X = (X_{1}, X_{2}, X_{3}, 1)^{T}$ be a point in 3D. For two cameras, we have\n",
    "$$\n",
    "x_{1} = P_{1}X \\\\\n",
    "x_{2} = P_{2}X\n",
    "$$\n",
    "Triangulation is to solve X given x1, x2, P1, P2. We’ll use Direct Linear Transform (DLT) to perform triangulation, which has already been implemented in OpenCV.\n",
    "\n",
    "Here are the instructions:\n",
    "1. Load camera intrinsic matrix $K_{1}$ and $K_{2}$ from temple.npz.\n",
    "2. Extract the essential matrix E given the fundamental matrix F and intrinsic matrices $K_{1}$ and $K_{2}$.\n",
    "Report E. Recall that\n",
    "$$\n",
    "F = K^{−T}_{2} EK^{−1}_{1}\n",
    "$$\n",
    "For this question, you may use cv2.findFundamentalMat to obtain the Fundamental matrix.\n",
    "3. Decompose the essential matrix E and get the rotation matrix R and translation t. You can use\n",
    "cv2.decomposeEssentialMat. Hint: There are four possible combinations of R and t. The\n",
    "correct configuration is the one for which most of the 3D points are in front of both cameras (positive\n",
    "depth).\n",
    "4. Determine the camera projection matrices P1 and P2 according to the intrinsic and extrinsic matrix\n",
    "[R|t], K1 and K2. Report P1 and P2. You can set\n",
    "$$\n",
    "P_{1} = K_{1}[I\\quad 0] \\\\\n",
    "P_{2} = K_{2}[R\\quad t]\n",
    "$$\n",
    "5. Triangulate 2D pairs of points to 3D. You can use cv2.triangulatePoints.\n",
    "6. Visualize the point cloud. **Include** the visualization in your report from at least 3 views (so that we\n",
    "can reconstruct it!). A sample output is shown as Figure 3. You may use our provided visualization\n",
    "function, visualize pcd found in utils.py, or you can implement your own visualization. One\n",
    "good alternative is matplotlib’s 3D scatterplot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba638da1d2555046f6c036f3b55f96640e14b9ae1bacb866420559fab20bdea2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
